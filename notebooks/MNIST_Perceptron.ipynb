{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BcLhx7R4YuUv"
   },
   "source": [
    "# MNIST in Swift for TensorFlow (Perceptron)\n",
    "\n",
    "Blog post: https://rickwierenga.com/blog/s4tf/s4tf-mnist.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lvZux3i-YzNv"
   },
   "source": [
    "## Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dvaI1fPZRfQH"
   },
   "outputs": [],
   "source": [
    "import TensorFlow\n",
    "import Foundation\n",
    "import FoundationNetworking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0awo42kpWWaE"
   },
   "outputs": [],
   "source": [
    "import Python\n",
    "let plt = Python.import(\"matplotlib.pylab\")\n",
    "let np = Python.import(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hxyQaWVajlrA"
   },
   "outputs": [],
   "source": [
    "%include \"EnableIPythonDisplay.swift\"\n",
    "IPythonDisplay.shell.enable_matplotlib(\"inline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gFp59EhiY3Y4"
   },
   "source": [
    "## Loading MNIST\n",
    "\n",
    "Recreating much of the MNIST API in https://github.com/tensorflow/swift-models, because it is not currently working in Colab. The team told us they are working on an update. (https://github.com/tensorflow/swift-models/issues/233)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rWW7r5kOG2zz"
   },
   "outputs": [],
   "source": [
    "public struct LabeledExample: TensorGroup {\n",
    "    public var label: Tensor<Int32>\n",
    "    public var data: Tensor<Float>\n",
    "\n",
    "    public init(label: Tensor<Int32>, data: Tensor<Float>) {\n",
    "        self.label = label\n",
    "        self.data = data\n",
    "    }\n",
    "\n",
    "    public init<C: RandomAccessCollection>(\n",
    "        _handles: C\n",
    "    ) where C.Element: _AnyTensorHandle {\n",
    "        precondition(_handles.count == 2)\n",
    "        let labelIndex = _handles.startIndex\n",
    "        let dataIndex = _handles.index(labelIndex, offsetBy: 1)\n",
    "        label = Tensor<Int32>(handle: TensorHandle<Int32>(handle: _handles[labelIndex]))\n",
    "        data = Tensor<Float>(handle: TensorHandle<Float>(handle: _handles[dataIndex]))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CTwdxXDJF_vX"
   },
   "outputs": [],
   "source": [
    "public struct DatasetUtilities {\n",
    "    public static let currentWorkingDirectoryURL = URL(\n",
    "        fileURLWithPath: FileManager.default.currentDirectoryPath)\n",
    "\n",
    "    public static func fetchResource(\n",
    "        filename: String,\n",
    "        remoteRoot: URL,\n",
    "        localStorageDirectory: URL = currentWorkingDirectoryURL\n",
    "    ) -> Data {\n",
    "        print(\"Loading resource: \\(filename)\")\n",
    "\n",
    "        let resource = ResourceDefinition(\n",
    "            filename: filename,\n",
    "            remoteRoot: remoteRoot,\n",
    "            localStorageDirectory: localStorageDirectory)\n",
    "\n",
    "        let localURL = resource.localURL\n",
    "\n",
    "        if !FileManager.default.fileExists(atPath: localURL.path) {\n",
    "            print(\n",
    "                \"File does not exist locally at expected path: \\(localURL.path) and must be fetched\"\n",
    "            )\n",
    "            fetchFromRemoteAndSave(resource)\n",
    "        }\n",
    "\n",
    "        do {\n",
    "            print(\"Loading local data at: \\(localURL.path)\")\n",
    "            let data = try Data(contentsOf: localURL)\n",
    "            print(\"Succesfully loaded resource: \\(filename)\")\n",
    "            return data\n",
    "        } catch {\n",
    "            fatalError(\"Failed to contents of resource: \\(localURL)\")\n",
    "        }\n",
    "    }\n",
    "\n",
    "    struct ResourceDefinition {\n",
    "        let filename: String\n",
    "        let remoteRoot: URL\n",
    "        let localStorageDirectory: URL\n",
    "\n",
    "        var localURL: URL {\n",
    "            localStorageDirectory.appendingPathComponent(filename)\n",
    "        }\n",
    "\n",
    "        var remoteURL: URL {\n",
    "            remoteRoot.appendingPathComponent(filename).appendingPathExtension(\"gz\")\n",
    "        }\n",
    "\n",
    "        var archiveURL: URL {\n",
    "            localURL.appendingPathExtension(\"gz\")\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static func fetchFromRemoteAndSave(_ resource: ResourceDefinition) {\n",
    "        let remoteLocation = resource.remoteURL\n",
    "        let archiveLocation = resource.archiveURL\n",
    "\n",
    "        do {\n",
    "            print(\"Fetching URL: \\(remoteLocation)...\")\n",
    "            let archiveData = try Data(contentsOf: remoteLocation)\n",
    "            print(\"Writing fetched archive to: \\(archiveLocation.path)\")\n",
    "            try archiveData.write(to: archiveLocation)\n",
    "        } catch {\n",
    "            fatalError(\"Failed to fetch and save resource with error: \\(error)\")\n",
    "        }\n",
    "        print(\"Archive saved to: \\(archiveLocation.path)\")\n",
    "\n",
    "        extractArchive(for: resource)\n",
    "    }\n",
    "\n",
    "    static func extractArchive(for resource: ResourceDefinition) {\n",
    "        print(\"Extracting archive...\")\n",
    "\n",
    "        let archivePath = resource.archiveURL.path\n",
    "\n",
    "        #if os(macOS)\n",
    "            let gunzipLocation = \"/usr/bin/gunzip\"\n",
    "        #else\n",
    "            let gunzipLocation = \"/bin/gunzip\"\n",
    "        #endif\n",
    "\n",
    "        let task = Process()\n",
    "        task.executableURL = URL(fileURLWithPath: gunzipLocation)\n",
    "        task.arguments = [archivePath]\n",
    "        do {\n",
    "            try task.run()\n",
    "            task.waitUntilExit()\n",
    "        } catch {\n",
    "            fatalError(\"Failed to extract \\(archivePath) with error: \\(error)\")\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tbzz4INnRnTh"
   },
   "outputs": [],
   "source": [
    "public struct MNIST {\n",
    "    public let trainingDataset: Dataset<LabeledExample>\n",
    "    public let testDataset: Dataset<LabeledExample>\n",
    "    public let trainingExampleCount = 60000\n",
    "\n",
    "    public init() {\n",
    "        self.init(flattening: false, normalizing: false)\n",
    "    }\n",
    "\n",
    "    public init(\n",
    "        flattening: Bool = false, normalizing: Bool = false,\n",
    "        localStorageDirectory: URL = DatasetUtilities.currentWorkingDirectoryURL\n",
    "    ) {\n",
    "        self.trainingDataset = Dataset<LabeledExample>(\n",
    "            elements: fetchDataset(\n",
    "                localStorageDirectory: localStorageDirectory,\n",
    "                imagesFilename: \"train-images-idx3-ubyte\",\n",
    "                labelsFilename: \"train-labels-idx1-ubyte\",\n",
    "                flattening: flattening,\n",
    "                normalizing: normalizing))\n",
    "\n",
    "        self.testDataset = Dataset<LabeledExample>(\n",
    "            elements: fetchDataset(\n",
    "                localStorageDirectory: localStorageDirectory,\n",
    "                imagesFilename: \"t10k-images-idx3-ubyte\",\n",
    "                labelsFilename: \"t10k-labels-idx1-ubyte\",\n",
    "                flattening: flattening,\n",
    "                normalizing: normalizing))\n",
    "    }\n",
    "}\n",
    "\n",
    "fileprivate func fetchDataset(\n",
    "    localStorageDirectory: URL,\n",
    "    imagesFilename: String,\n",
    "    labelsFilename: String,\n",
    "    flattening: Bool,\n",
    "    normalizing: Bool\n",
    ") -> LabeledExample {\n",
    "    guard let remoteRoot:URL = URL(string: \"http://yann.lecun.com/exdb/mnist\") else {\n",
    "        fatalError(\"Failed to create MNST root url: http://yann.lecun.com/exdb/mnist\")\n",
    "    }\n",
    "\n",
    "    let imagesData = DatasetUtilities.fetchResource(\n",
    "        filename: imagesFilename,\n",
    "        remoteRoot: remoteRoot,\n",
    "        localStorageDirectory: localStorageDirectory)\n",
    "    let labelsData = DatasetUtilities.fetchResource(\n",
    "        filename: labelsFilename,\n",
    "        remoteRoot: remoteRoot,\n",
    "        localStorageDirectory: localStorageDirectory)\n",
    "\n",
    "    let images = [UInt8](imagesData).dropFirst(16).map(Float.init)\n",
    "    let labels = [UInt8](labelsData).dropFirst(8).map(Int32.init)\n",
    "\n",
    "    let rowCount = labels.count\n",
    "    let (imageWidth, imageHeight) = (28, 28)\n",
    "\n",
    "    if flattening {\n",
    "        var flattenedImages = Tensor(shape: [rowCount, imageHeight * imageWidth], scalars: images)\n",
    "            / 255.0\n",
    "        if normalizing {\n",
    "            flattenedImages = flattenedImages * 2.0 - 1.0\n",
    "        }\n",
    "        return LabeledExample(label: Tensor(labels), data: flattenedImages)\n",
    "    } else {\n",
    "        return LabeledExample(\n",
    "            label: Tensor(labels),\n",
    "            data:\n",
    "                Tensor(shape: [rowCount, 1, imageHeight, imageWidth], scalars: images)\n",
    "                .transposed(withPermutations: [0, 2, 3, 1]) / 255  // NHWC\n",
    "        )\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cmEkbL2UHP2r"
   },
   "outputs": [],
   "source": [
    "let mnist = MNIST(flattening: false, normalizing: true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ppaI_0SZKh2"
   },
   "source": [
    "## Constructing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k-hGkSXkRux3"
   },
   "outputs": [],
   "source": [
    "struct Model: Layer {\n",
    "    var flatten = Flatten<Float>()\n",
    "    var hiddenLayer = Dense<Float>(inputSize: 28 * 28, outputSize: 300, activation: relu)\n",
    "    var outputLayer = Dense<Float>(inputSize: 300, outputSize: 10, activation: softmax)\n",
    "\n",
    "    @differentiable\n",
    "    func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        return input.sequenced(through: flatten, hiddenLayer, outputLayer)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5XCYHPH_qPaz"
   },
   "outputs": [],
   "source": [
    "var model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qAXVzcGFZTAn"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a7BG7EpeIuqp"
   },
   "outputs": [],
   "source": [
    "let batchSize = 512\n",
    "let epochs = 10\n",
    "let testBatches = mnist.testDataset.batched(batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "px-gCWe7gSJp"
   },
   "outputs": [],
   "source": [
    "var trainHistory = np.zeros(epochs)\n",
    "var valHistory = np.zeros(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GvM422SwOyvN"
   },
   "outputs": [],
   "source": [
    "let optimizer = Adam(for: model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bdqKlxmpHkc7"
   },
   "outputs": [],
   "source": [
    "for epoch in 0..<epochs {\n",
    "    // Update parameters\n",
    "    Context.local.learningPhase = .training\n",
    "    let trainingShuffled = mnist.trainingDataset.shuffled(sampleCount: mnist.trainingExampleCount, randomSeed: Int64(epoch))\n",
    "    for batch in trainingShuffled.batched(batchSize) {\n",
    "        let (labels, images) = (batch.label, batch.data.reshaped(to: TensorShape(batch.data.shape[0], 28, 28, 1)))\n",
    "        let (_, gradients) = valueWithGradient(at: model) { model -> Tensor<Float> in\n",
    "            let logits = model(images)\n",
    "            return softmaxCrossEntropy(logits: logits, labels: labels)\n",
    "        }\n",
    "        optimizer.update(&model, along: gradients)\n",
    "    }\n",
    "\n",
    "    // Evaluate model\n",
    "    Context.local.learningPhase = .inference\n",
    "\n",
    "    var correctTrainGuessCount = 0\n",
    "    var totalTrainGuessCount = 0\n",
    "    for batch in mnist.trainingDataset.batched(batchSize) {\n",
    "        let (labels, images) = (batch.label, batch.data.reshaped(to: TensorShape(batch.data.shape[0], 28, 28, 1)))\n",
    "        let logits = model(images)\n",
    "        let correctPredictions = logits.argmax(squeezingAxis: 1) .== labels\n",
    "        correctTrainGuessCount += Int(Tensor<Int32>(correctPredictions).sum().scalarized())\n",
    "        totalTrainGuessCount += batch.data.shape[0]\n",
    "    }\n",
    "    let trainAcc = Float(correctTrainGuessCount) / Float(totalTrainGuessCount)\n",
    "    trainHistory[epoch] = PythonObject(trainAcc)\n",
    "\n",
    "    var correctValGuessCount = 0\n",
    "    var totalValGuessCount = 0\n",
    "    for batch in testBatches {\n",
    "        let (labels, images) = (batch.label, batch.data.reshaped(to: TensorShape(batch.data.shape[0], 28, 28, 1)))\n",
    "        let logits = model(images)\n",
    "        let correctPredictions = logits.argmax(squeezingAxis: 1) .== labels\n",
    "        correctValGuessCount += Int(Tensor<Int32>(correctPredictions).sum().scalarized())\n",
    "        totalValGuessCount += batch.data.shape[0]\n",
    "    }\n",
    "    let valAcc = Float(correctValGuessCount) / Float(totalValGuessCount)\n",
    "    valHistory[epoch] = PythonObject(valAcc)\n",
    "    \n",
    "    print(\"\\(epoch) | Training accuracy: \\(trainAcc) | Validation accuracy: \\(valAcc)\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WjUY0gwXTDX-"
   },
   "source": [
    "## Inspecting training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b_f-DNeqp9qO"
   },
   "outputs": [],
   "source": [
    "plt.plot(trainHistory)\n",
    "plt.title(\"Training History\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1AkaTk_3THsK"
   },
   "outputs": [],
   "source": [
    "plt.plot(valHistory)\n",
    "plt.title(\"Validation History\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "S4TF MNIST ConvNet.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
