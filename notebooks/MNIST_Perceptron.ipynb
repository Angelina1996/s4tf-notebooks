{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S4TF MNIST ConvNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "swift",
      "display_name": "Swift"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcLhx7R4YuUv",
        "colab_type": "text"
      },
      "source": [
        "# MNIST in Swift for TensorFlow (ConvNet)\n",
        "\n",
        "Blog post: https://rickwierenga.com/blog/s4tf/s4tf-mnist.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvZux3i-YzNv",
        "colab_type": "text"
      },
      "source": [
        "## Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvaI1fPZRfQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import TensorFlow\n",
        "import Foundation\n",
        "import FoundationNetworking"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0awo42kpWWaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Python\n",
        "let plt = Python.import(\"matplotlib.pylab\")\n",
        "let np = Python.import(\"numpy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxyQaWVajlrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%include \"EnableIPythonDisplay.swift\"\n",
        "IPythonDisplay.shell.enable_matplotlib(\"inline\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFp59EhiY3Y4",
        "colab_type": "text"
      },
      "source": [
        "## Loading MNIST\n",
        "\n",
        "Recreating much of the MNIST API in https://github.com/tensorflow/swift-models, because it is not currently working in Colab. The team told us they are working on an update. (https://github.com/tensorflow/swift-models/issues/233)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWW7r5kOG2zz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "public struct LabeledExample: TensorGroup {\n",
        "    public var label: Tensor<Int32>\n",
        "    public var data: Tensor<Float>\n",
        "\n",
        "    public init(label: Tensor<Int32>, data: Tensor<Float>) {\n",
        "        self.label = label\n",
        "        self.data = data\n",
        "    }\n",
        "\n",
        "    public init<C: RandomAccessCollection>(\n",
        "        _handles: C\n",
        "    ) where C.Element: _AnyTensorHandle {\n",
        "        precondition(_handles.count == 2)\n",
        "        let labelIndex = _handles.startIndex\n",
        "        let dataIndex = _handles.index(labelIndex, offsetBy: 1)\n",
        "        label = Tensor<Int32>(handle: TensorHandle<Int32>(handle: _handles[labelIndex]))\n",
        "        data = Tensor<Float>(handle: TensorHandle<Float>(handle: _handles[dataIndex]))\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTwdxXDJF_vX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "public struct DatasetUtilities {\n",
        "    public static let currentWorkingDirectoryURL = URL(\n",
        "        fileURLWithPath: FileManager.default.currentDirectoryPath)\n",
        "\n",
        "    public static func fetchResource(\n",
        "        filename: String,\n",
        "        remoteRoot: URL,\n",
        "        localStorageDirectory: URL = currentWorkingDirectoryURL\n",
        "    ) -> Data {\n",
        "        print(\"Loading resource: \\(filename)\")\n",
        "\n",
        "        let resource = ResourceDefinition(\n",
        "            filename: filename,\n",
        "            remoteRoot: remoteRoot,\n",
        "            localStorageDirectory: localStorageDirectory)\n",
        "\n",
        "        let localURL = resource.localURL\n",
        "\n",
        "        if !FileManager.default.fileExists(atPath: localURL.path) {\n",
        "            print(\n",
        "                \"File does not exist locally at expected path: \\(localURL.path) and must be fetched\"\n",
        "            )\n",
        "            fetchFromRemoteAndSave(resource)\n",
        "        }\n",
        "\n",
        "        do {\n",
        "            print(\"Loading local data at: \\(localURL.path)\")\n",
        "            let data = try Data(contentsOf: localURL)\n",
        "            print(\"Succesfully loaded resource: \\(filename)\")\n",
        "            return data\n",
        "        } catch {\n",
        "            fatalError(\"Failed to contents of resource: \\(localURL)\")\n",
        "        }\n",
        "    }\n",
        "\n",
        "    struct ResourceDefinition {\n",
        "        let filename: String\n",
        "        let remoteRoot: URL\n",
        "        let localStorageDirectory: URL\n",
        "\n",
        "        var localURL: URL {\n",
        "            localStorageDirectory.appendingPathComponent(filename)\n",
        "        }\n",
        "\n",
        "        var remoteURL: URL {\n",
        "            remoteRoot.appendingPathComponent(filename).appendingPathExtension(\"gz\")\n",
        "        }\n",
        "\n",
        "        var archiveURL: URL {\n",
        "            localURL.appendingPathExtension(\"gz\")\n",
        "        }\n",
        "    }\n",
        "\n",
        "    static func fetchFromRemoteAndSave(_ resource: ResourceDefinition) {\n",
        "        let remoteLocation = resource.remoteURL\n",
        "        let archiveLocation = resource.archiveURL\n",
        "\n",
        "        do {\n",
        "            print(\"Fetching URL: \\(remoteLocation)...\")\n",
        "            let archiveData = try Data(contentsOf: remoteLocation)\n",
        "            print(\"Writing fetched archive to: \\(archiveLocation.path)\")\n",
        "            try archiveData.write(to: archiveLocation)\n",
        "        } catch {\n",
        "            fatalError(\"Failed to fetch and save resource with error: \\(error)\")\n",
        "        }\n",
        "        print(\"Archive saved to: \\(archiveLocation.path)\")\n",
        "\n",
        "        extractArchive(for: resource)\n",
        "    }\n",
        "\n",
        "    static func extractArchive(for resource: ResourceDefinition) {\n",
        "        print(\"Extracting archive...\")\n",
        "\n",
        "        let archivePath = resource.archiveURL.path\n",
        "\n",
        "        #if os(macOS)\n",
        "            let gunzipLocation = \"/usr/bin/gunzip\"\n",
        "        #else\n",
        "            let gunzipLocation = \"/bin/gunzip\"\n",
        "        #endif\n",
        "\n",
        "        let task = Process()\n",
        "        task.executableURL = URL(fileURLWithPath: gunzipLocation)\n",
        "        task.arguments = [archivePath]\n",
        "        do {\n",
        "            try task.run()\n",
        "            task.waitUntilExit()\n",
        "        } catch {\n",
        "            fatalError(\"Failed to extract \\(archivePath) with error: \\(error)\")\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbzz4INnRnTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "public struct MNIST {\n",
        "    public let trainingDataset: Dataset<LabeledExample>\n",
        "    public let testDataset: Dataset<LabeledExample>\n",
        "    public let trainingExampleCount = 60000\n",
        "\n",
        "    public init() {\n",
        "        self.init(flattening: false, normalizing: false)\n",
        "    }\n",
        "\n",
        "    public init(\n",
        "        flattening: Bool = false, normalizing: Bool = false,\n",
        "        localStorageDirectory: URL = DatasetUtilities.currentWorkingDirectoryURL\n",
        "    ) {\n",
        "        self.trainingDataset = Dataset<LabeledExample>(\n",
        "            elements: fetchDataset(\n",
        "                localStorageDirectory: localStorageDirectory,\n",
        "                imagesFilename: \"train-images-idx3-ubyte\",\n",
        "                labelsFilename: \"train-labels-idx1-ubyte\",\n",
        "                flattening: flattening,\n",
        "                normalizing: normalizing))\n",
        "\n",
        "        self.testDataset = Dataset<LabeledExample>(\n",
        "            elements: fetchDataset(\n",
        "                localStorageDirectory: localStorageDirectory,\n",
        "                imagesFilename: \"t10k-images-idx3-ubyte\",\n",
        "                labelsFilename: \"t10k-labels-idx1-ubyte\",\n",
        "                flattening: flattening,\n",
        "                normalizing: normalizing))\n",
        "    }\n",
        "}\n",
        "\n",
        "fileprivate func fetchDataset(\n",
        "    localStorageDirectory: URL,\n",
        "    imagesFilename: String,\n",
        "    labelsFilename: String,\n",
        "    flattening: Bool,\n",
        "    normalizing: Bool\n",
        ") -> LabeledExample {\n",
        "    guard let remoteRoot:URL = URL(string: \"http://yann.lecun.com/exdb/mnist\") else {\n",
        "        fatalError(\"Failed to create MNST root url: http://yann.lecun.com/exdb/mnist\")\n",
        "    }\n",
        "\n",
        "    let imagesData = DatasetUtilities.fetchResource(\n",
        "        filename: imagesFilename,\n",
        "        remoteRoot: remoteRoot,\n",
        "        localStorageDirectory: localStorageDirectory)\n",
        "    let labelsData = DatasetUtilities.fetchResource(\n",
        "        filename: labelsFilename,\n",
        "        remoteRoot: remoteRoot,\n",
        "        localStorageDirectory: localStorageDirectory)\n",
        "\n",
        "    let images = [UInt8](imagesData).dropFirst(16).map(Float.init)\n",
        "    let labels = [UInt8](labelsData).dropFirst(8).map(Int32.init)\n",
        "\n",
        "    let rowCount = labels.count\n",
        "    let (imageWidth, imageHeight) = (28, 28)\n",
        "\n",
        "    if flattening {\n",
        "        var flattenedImages = Tensor(shape: [rowCount, imageHeight * imageWidth], scalars: images)\n",
        "            / 255.0\n",
        "        if normalizing {\n",
        "            flattenedImages = flattenedImages * 2.0 - 1.0\n",
        "        }\n",
        "        return LabeledExample(label: Tensor(labels), data: flattenedImages)\n",
        "    } else {\n",
        "        return LabeledExample(\n",
        "            label: Tensor(labels),\n",
        "            data:\n",
        "                Tensor(shape: [rowCount, 1, imageHeight, imageWidth], scalars: images)\n",
        "                .transposed(withPermutations: [0, 2, 3, 1]) / 255  // NHWC\n",
        "        )\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmEkbL2UHP2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let mnist = MNIST(flattening: false, normalizing: true)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ppaI_0SZKh2",
        "colab_type": "text"
      },
      "source": [
        "## Constructing the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-hGkSXkRux3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "struct Model: Layer {\n",
        "    var hiddenLayer = Dense<Float>(inputSize: 28 * 28, outputSize: 300, activation: relu)\n",
        "    var outputLayer = Dense<Float>(inputSize: 300, outputSize: 10, activation: softmax)\n",
        "\n",
        "    @differentiable\n",
        "    func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
        "        return input.sequenced(through: hiddenLayer, outputLayer)\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XCYHPH_qPaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var model = Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAXVzcGFZTAn",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7BG7EpeIuqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let batchSize = 512\n",
        "let epochs = 10\n",
        "let testBatches = mnist.testDataset.batched(batchSize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px-gCWe7gSJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var trainHistory = np.zeros(epochs)\n",
        "var valHistory = np.zeros(epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvM422SwOyvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let optimizer = Adam(for: model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdqKlxmpHkc7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in 0..<epochs {\n",
        "    // Update parameters\n",
        "    Context.local.learningPhase = .training\n",
        "    let trainingShuffled = mnist.trainingDataset.shuffled(sampleCount: mnist.trainingExampleCount, randomSeed: Int64(epoch))\n",
        "    for batch in trainingShuffled.batched(batchSize) {\n",
        "        let (labels, images) = (batch.label, batch.data.reshaped(to: TensorShape(batch.data.shape[0], 28, 28, 1)))\n",
        "        let (_, gradients) = valueWithGradient(at: model) { model -> Tensor<Float> in\n",
        "            let logits = model(images)\n",
        "            return softmaxCrossEntropy(logits: logits, labels: labels)\n",
        "        }\n",
        "        optimizer.update(&model, along: gradients)\n",
        "    }\n",
        "\n",
        "    // Evaluate model\n",
        "    Context.local.learningPhase = .inference\n",
        "\n",
        "    var correctTrainGuessCount = 0\n",
        "    var totalTrainGuessCount = 0\n",
        "    for batch in mnist.trainingDataset.batched(batchSize) {\n",
        "        let (labels, images) = (batch.label, batch.data.reshaped(to: TensorShape(batch.data.shape[0], 28, 28, 1)))\n",
        "        let logits = model(images)\n",
        "        let correctPredictions = logits.argmax(squeezingAxis: 1) .== labels\n",
        "        correctTrainGuessCount += Int(Tensor<Int32>(correctPredictions).sum().scalarized())\n",
        "        totalTrainGuessCount += batch.data.shape[0]\n",
        "    }\n",
        "    let trainAcc = Float(correctTrainGuessCount) / Float(totalTrainGuessCount)\n",
        "    trainHistory[epoch] = PythonObject(trainAcc)\n",
        "\n",
        "    var correctValGuessCount = 0\n",
        "    var totalValGuessCount = 0\n",
        "    for batch in testBatches {\n",
        "        let (labels, images) = (batch.label, batch.data.reshaped(to: TensorShape(batch.data.shape[0], 28, 28, 1)))\n",
        "        let logits = model(images)\n",
        "        let correctPredictions = logits.argmax(squeezingAxis: 1) .== labels\n",
        "        correctValGuessCount += Int(Tensor<Int32>(correctPredictions).sum().scalarized())\n",
        "        totalValGuessCount += batch.data.shape[0]\n",
        "    }\n",
        "    let valAcc = Float(correctValGuessCount) / Float(totalValGuessCount)\n",
        "    valHistory[epoch] = PythonObject(valAcc)\n",
        "    \n",
        "    print(\"\\(epoch) | Training accuracy: \\(trainAcc) | Validation accuracy: \\(valAcc)\")\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjUY0gwXTDX-",
        "colab_type": "text"
      },
      "source": [
        "## Inspecting training history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_f-DNeqp9qO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(trainHistory)\n",
        "plt.title(\"Training History\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AkaTk_3THsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(valHistory)\n",
        "plt.title(\"Validation History\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}