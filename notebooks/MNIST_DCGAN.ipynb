{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S4TF MNIST GAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "swift",
      "display_name": "Swift"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcLhx7R4YuUv",
        "colab_type": "text"
      },
      "source": [
        "# MNIST GAN in Swift for TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvZux3i-YzNv",
        "colab_type": "text"
      },
      "source": [
        "## Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvaI1fPZRfQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import TensorFlow\n",
        "import Foundation\n",
        "import FoundationNetworking"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eXM0Elku26P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%include \"EnableIPythonDisplay.swift\"\n",
        "IPythonDisplay.shell.enable_matplotlib(\"inline\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44nZFdVw2yyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Python\n",
        "let plt = Python.import(\"matplotlib.pyplot\")\n",
        "let np = Python.import(\"numpy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFp59EhiY3Y4",
        "colab_type": "text"
      },
      "source": [
        "## Loading MNIST\n",
        "\n",
        "Recreating much of the MNIST API in https://github.com/tensorflow/swift-models, because it is not currently working in Colab. The team told us they are working on an update. (https://github.com/tensorflow/swift-models/issues/233)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbzz4INnRnTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "public struct LabeledExample: TensorGroup {\n",
        "    public var label: Tensor<Int32>\n",
        "    public var data: Tensor<Float>\n",
        "\n",
        "    public init(label: Tensor<Int32>, data: Tensor<Float>) {\n",
        "        self.label = label\n",
        "        self.data = data\n",
        "    }\n",
        "\n",
        "    public init<C: RandomAccessCollection>(\n",
        "        _handles: C\n",
        "    ) where C.Element: _AnyTensorHandle {\n",
        "        precondition(_handles.count == 2)\n",
        "        let labelIndex = _handles.startIndex\n",
        "        let dataIndex = _handles.index(labelIndex, offsetBy: 1)\n",
        "        label = Tensor<Int32>(handle: TensorHandle<Int32>(handle: _handles[labelIndex]))\n",
        "        data = Tensor<Float>(handle: TensorHandle<Float>(handle: _handles[dataIndex]))\n",
        "    }\n",
        "}\n",
        "\n",
        "public struct DatasetUtilities {\n",
        "    public static let currentWorkingDirectoryURL = URL(\n",
        "        fileURLWithPath: FileManager.default.currentDirectoryPath)\n",
        "\n",
        "    public static func fetchResource(\n",
        "        filename: String,\n",
        "        remoteRoot: URL,\n",
        "        localStorageDirectory: URL = currentWorkingDirectoryURL\n",
        "    ) -> Data {\n",
        "        print(\"Loading resource: \\(filename)\")\n",
        "\n",
        "        let resource = ResourceDefinition(\n",
        "            filename: filename,\n",
        "            remoteRoot: remoteRoot,\n",
        "            localStorageDirectory: localStorageDirectory)\n",
        "\n",
        "        let localURL = resource.localURL\n",
        "\n",
        "        if !FileManager.default.fileExists(atPath: localURL.path) {\n",
        "            print(\n",
        "                \"File does not exist locally at expected path: \\(localURL.path) and must be fetched\"\n",
        "            )\n",
        "            fetchFromRemoteAndSave(resource)\n",
        "        }\n",
        "\n",
        "        do {\n",
        "            print(\"Loading local data at: \\(localURL.path)\")\n",
        "            let data = try Data(contentsOf: localURL)\n",
        "            print(\"Succesfully loaded resource: \\(filename)\")\n",
        "            return data\n",
        "        } catch {\n",
        "            fatalError(\"Failed to contents of resource: \\(localURL)\")\n",
        "        }\n",
        "    }\n",
        "\n",
        "    struct ResourceDefinition {\n",
        "        let filename: String\n",
        "        let remoteRoot: URL\n",
        "        let localStorageDirectory: URL\n",
        "\n",
        "        var localURL: URL {\n",
        "            localStorageDirectory.appendingPathComponent(filename)\n",
        "        }\n",
        "\n",
        "        var remoteURL: URL {\n",
        "            remoteRoot.appendingPathComponent(filename).appendingPathExtension(\"gz\")\n",
        "        }\n",
        "\n",
        "        var archiveURL: URL {\n",
        "            localURL.appendingPathExtension(\"gz\")\n",
        "        }\n",
        "    }\n",
        "\n",
        "    static func fetchFromRemoteAndSave(_ resource: ResourceDefinition) {\n",
        "        let remoteLocation = resource.remoteURL\n",
        "        let archiveLocation = resource.archiveURL\n",
        "\n",
        "        do {\n",
        "            print(\"Fetching URL: \\(remoteLocation)...\")\n",
        "            let archiveData = try Data(contentsOf: remoteLocation)\n",
        "            print(\"Writing fetched archive to: \\(archiveLocation.path)\")\n",
        "            try archiveData.write(to: archiveLocation)\n",
        "        } catch {\n",
        "            fatalError(\"Failed to fetch and save resource with error: \\(error)\")\n",
        "        }\n",
        "        print(\"Archive saved to: \\(archiveLocation.path)\")\n",
        "\n",
        "        extractArchive(for: resource)\n",
        "    }\n",
        "\n",
        "    static func extractArchive(for resource: ResourceDefinition) {\n",
        "        print(\"Extracting archive...\")\n",
        "\n",
        "        let archivePath = resource.archiveURL.path\n",
        "\n",
        "        #if os(macOS)\n",
        "            let gunzipLocation = \"/usr/bin/gunzip\"\n",
        "        #else\n",
        "            let gunzipLocation = \"/bin/gunzip\"\n",
        "        #endif\n",
        "\n",
        "        let task = Process()\n",
        "        task.executableURL = URL(fileURLWithPath: gunzipLocation)\n",
        "        task.arguments = [archivePath]\n",
        "        do {\n",
        "            try task.run()\n",
        "            task.waitUntilExit()\n",
        "        } catch {\n",
        "            fatalError(\"Failed to extract \\(archivePath) with error: \\(error)\")\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "public struct MNIST {\n",
        "    public let trainingDataset: Dataset<LabeledExample>\n",
        "    public let testDataset: Dataset<LabeledExample>\n",
        "    public let trainingExampleCount = 60000\n",
        "\n",
        "    public init() {\n",
        "        self.init(flattening: false, normalizing: false)\n",
        "    }\n",
        "\n",
        "    public init(\n",
        "        flattening: Bool = false, normalizing: Bool = false,\n",
        "        localStorageDirectory: URL = DatasetUtilities.currentWorkingDirectoryURL\n",
        "    ) {\n",
        "        self.trainingDataset = Dataset<LabeledExample>(\n",
        "            elements: fetchDataset(\n",
        "                localStorageDirectory: localStorageDirectory,\n",
        "                imagesFilename: \"train-images-idx3-ubyte\",\n",
        "                labelsFilename: \"train-labels-idx1-ubyte\",\n",
        "                flattening: flattening,\n",
        "                normalizing: normalizing))\n",
        "\n",
        "        self.testDataset = Dataset<LabeledExample>(\n",
        "            elements: fetchDataset(\n",
        "                localStorageDirectory: localStorageDirectory,\n",
        "                imagesFilename: \"t10k-images-idx3-ubyte\",\n",
        "                labelsFilename: \"t10k-labels-idx1-ubyte\",\n",
        "                flattening: flattening,\n",
        "                normalizing: normalizing))\n",
        "    }\n",
        "}\n",
        "\n",
        "fileprivate func fetchDataset(\n",
        "    localStorageDirectory: URL,\n",
        "    imagesFilename: String,\n",
        "    labelsFilename: String,\n",
        "    flattening: Bool,\n",
        "    normalizing: Bool\n",
        ") -> LabeledExample {\n",
        "    guard let remoteRoot:URL = URL(string: \"http://yann.lecun.com/exdb/mnist\") else {\n",
        "        fatalError(\"Failed to create MNST root url: http://yann.lecun.com/exdb/mnist\")\n",
        "    }\n",
        "\n",
        "    let imagesData = DatasetUtilities.fetchResource(\n",
        "        filename: imagesFilename,\n",
        "        remoteRoot: remoteRoot,\n",
        "        localStorageDirectory: localStorageDirectory)\n",
        "    let labelsData = DatasetUtilities.fetchResource(\n",
        "        filename: labelsFilename,\n",
        "        remoteRoot: remoteRoot,\n",
        "        localStorageDirectory: localStorageDirectory)\n",
        "\n",
        "    let images = [UInt8](imagesData).dropFirst(16).map(Float.init)\n",
        "    let labels = [UInt8](labelsData).dropFirst(8).map(Int32.init)\n",
        "\n",
        "    let rowCount = labels.count\n",
        "    let (imageWidth, imageHeight) = (28, 28)\n",
        "\n",
        "    if flattening {\n",
        "        var flattenedImages = Tensor(shape: [rowCount, imageHeight * imageWidth], scalars: images)\n",
        "            / 255.0\n",
        "        if normalizing {\n",
        "            flattenedImages = flattenedImages * 2.0 - 1.0\n",
        "        }\n",
        "        return LabeledExample(label: Tensor(labels), data: flattenedImages)\n",
        "    } else {\n",
        "        return LabeledExample(\n",
        "            label: Tensor(labels),\n",
        "            data:\n",
        "                Tensor(shape: [rowCount, 1, imageHeight, imageWidth], scalars: images)\n",
        "                .transposed(withPermutations: [0, 2, 3, 1]) / 255  // NHWC\n",
        "        )\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDEoKPPYZRGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let mnist = MNIST(flattening: false, normalizing: true)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ppaI_0SZKh2",
        "colab_type": "text"
      },
      "source": [
        "## Building a DCGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzGTKJc0u8fw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let zDim = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHjdUaVosD_2",
        "colab_type": "text"
      },
      "source": [
        "### Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywzfKlWZsGm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "struct Generator: Layer {\n",
        "    var flatten = Flatten<Float>()\n",
        "\n",
        "    var dense1 = Dense<Float>(inputSize: zDim, outputSize: 7 * 7 * 256) \n",
        "    var batchNorm1 = BatchNorm<Float>(featureCount: 7 * 7 * 256)\n",
        "    // leaky relu\n",
        "    // reshape\n",
        "\n",
        "    var transConv2D1 = TransposedConv2D<Float>(\n",
        "        filterShape: (5, 5, 128, 256),\n",
        "        strides: (1, 1),\n",
        "        padding: .same\n",
        "    )\n",
        "    // flatten\n",
        "    var batchNorm2 = BatchNorm<Float>(featureCount: 7 * 7 * 128)\n",
        "    // leaky relu\n",
        "\n",
        "    var transConv2D2 = TransposedConv2D<Float>(\n",
        "        filterShape: (5, 5, 64, 128),\n",
        "        strides: (2, 2),\n",
        "        padding: .same\n",
        "    )\n",
        "    // flatten\n",
        "    var batchNorm3 = BatchNorm<Float>(featureCount: 14 * 14 * 64)\n",
        "    // leaky relu\n",
        "\n",
        "    var transConv2D3 = TransposedConv2D<Float>(\n",
        "        filterShape: (5, 5, 1, 64),\n",
        "        strides: (2, 2),\n",
        "        padding: .same\n",
        "    )\n",
        "    // tanh\n",
        "\n",
        "\n",
        "    @differentiable \n",
        "    public func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> { \n",
        "        let x1 = leakyRelu(input.sequenced(through: dense1, batchNorm1))\n",
        "        let x1Reshape = x1.reshaped(to: TensorShape(x1.shape.contiguousSize / (7 * 7 * 256), 7, 7, 256))\n",
        "        let x2 = leakyRelu(x1Reshape.sequenced(through: transConv2D1, flatten, batchNorm2))\n",
        "        let x2Reshape = x2.reshaped(to: TensorShape(x2.shape.contiguousSize / (7 * 7 * 128), 7, 7, 128))\n",
        "        let x3 = leakyRelu(x2Reshape.sequenced(through: transConv2D2, flatten, batchNorm3))\n",
        "        let x3Reshape = x3.reshaped(to: TensorShape(x3.shape.contiguousSize / (14 * 14 * 64), 14, 14, 64))\n",
        "        return tanh(transConv2D3(x3Reshape))\n",
        "    } \n",
        "} "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo6NLpr6vfds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var generator = Generator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stEdaj4QcM5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let noise = Tensor<Float>(randomNormal: TensorShape(1, zDim))\n",
        "let generatedImage = generator(noise)\n",
        "generatedImage.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PspNJrlnsMwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(generatedImage.reshaped(to: TensorShape(28, 28)).makeNumpyArray())\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpeMeZ-RxvHf",
        "colab_type": "text"
      },
      "source": [
        "### Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RyxKhl8DotBI",
        "colab": {}
      },
      "source": [
        "struct Discriminator: Layer {\n",
        "      var conv2D1 = Conv2D<Float>(\n",
        "          filterShape: (5, 5, 1, 64),\n",
        "          strides: (2, 2),\n",
        "          padding: .same\n",
        "      )\n",
        "      // leaky relu\n",
        "      var dropout = Dropout<Float>(probability: 0.3)\n",
        "\n",
        "      var conv2D2 = Conv2D<Float>(\n",
        "          filterShape: (5, 5, 64, 128),\n",
        "          strides: (2, 2),\n",
        "          padding: .same\n",
        "      )\n",
        "      // leaky relu\n",
        "      // dropout\n",
        "\n",
        "      var flatten = Flatten<Float>()\n",
        "      var dense = Dense<Float>(inputSize: 6272, outputSize: 1)\n",
        "\n",
        "      @differentiable \n",
        "      public func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> { \n",
        "          let x1 = dropout(leakyRelu(conv2D1(input)))\n",
        "          let x2 = dropout(leakyRelu(conv2D2(x1)))\n",
        "          return x2.sequenced(through: flatten, dense)\n",
        "      } \n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XCYHPH_qPaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var discriminator = Discriminator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz75syIpRv99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator(generatedImage)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAXVzcGFZTAn",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_PIfMBT3tMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let batchSize = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrlIsz38d0Bf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@differentiable\n",
        "func generatorLoss(fakeLabels: Tensor<Float>) -> Tensor<Float> {\n",
        "    sigmoidCrossEntropy(logits: fakeLabels,\n",
        "                        labels: Tensor(ones: fakeLabels.shape))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0CNw8avd0jR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@differentiable\n",
        "func discriminatorLoss(realLabels: Tensor<Float>, fakeLabels: Tensor<Float>) -> Tensor<Float> {\n",
        "    let realLoss = sigmoidCrossEntropy(logits: realLabels,\n",
        "                                       labels: Tensor(ones: realLabels.shape)) // should say it's real, 1\n",
        "    let fakeLoss = sigmoidCrossEntropy(logits: fakeLabels,\n",
        "                                       labels: Tensor(zeros: fakeLabels.shape)) // should say it's fake, 0\n",
        "    return realLoss + fakeLoss // accumaltive\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z14c8KOyqy4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let optG = Adam(for: generator, learningRate: 0.0001)\n",
        "let optD = Adam(for: discriminator, learningRate: 0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI6mNGO7oAJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let epochs = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnx_jDndZivO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in 0...epochs {\n",
        "    Context.local.learningPhase = .training\n",
        "    let trainingShuffled = mnist.trainingDataset.shuffled(sampleCount: mnist.trainingExampleCount, randomSeed: Int64(epoch))\n",
        "    for batch in trainingShuffled.batched(batchSize) {\n",
        "        let realImages = batch.data\n",
        "\n",
        "        // train generator\n",
        "        let noiseG = Tensor<Float>(randomNormal: TensorShape(batchSize, zDim))\n",
        "        let 𝛁generator = generator.gradient { generator -> Tensor<Float> in\n",
        "            let fakeImages = generator(noiseG)\n",
        "            let fakeLabels = discriminator(fakeImages)\n",
        "            let loss = generatorLoss(fakeLabels: fakeLabels)\n",
        "            return loss\n",
        "        }\n",
        "        optG.update(&generator, along: 𝛁generator)\n",
        "\n",
        "        // train discriminator\n",
        "        let noiseD = Tensor<Float>(randomNormal: TensorShape(batchSize, zDim))\n",
        "        let fakeImages = generator(noiseD)\n",
        "        \n",
        "        let 𝛁discriminator = discriminator.gradient { discriminator -> Tensor<Float> in\n",
        "            let realLabels = discriminator(realImages)\n",
        "            let fakeLabels = discriminator(fakeImages)\n",
        "            let loss = discriminatorLoss(realLabels: realLabels, fakeLabels: fakeLabels)\n",
        "            return loss\n",
        "        }\n",
        "        optD.update(&discriminator, along: 𝛁discriminator)\n",
        "    }\n",
        "\n",
        "    // test\n",
        "    Context.local.learningPhase = .inference\n",
        "\n",
        "    // render images\n",
        "    let generatedImage = generator(noise)\n",
        "    plt.imshow(generatedImage.reshaped(to: TensorShape(28, 28)).makeNumpyArray())\n",
        "    plt.show()\n",
        "    \n",
        "    // print loss\n",
        "    let generatorLoss_ = generatorLoss(fakeLabels: generatedImage)\n",
        "    print(\"epoch: \\(epoch) | Generator loss: \\(generatorLoss_)\")\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z_raHcVp2tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}